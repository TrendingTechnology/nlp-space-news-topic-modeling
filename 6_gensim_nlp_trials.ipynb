{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Gensim NLP trials](#gensim-nlp-trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from time import time\n",
    "from IPython.display import display\n",
    "\n",
    "import altair as alt\n",
    "import gensim.corpora as corpora\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from gensim.models import nmf, Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport src.pipe_helpers\n",
    "from src.pipe_helpers import TextCleaner\n",
    "\n",
    "%aimport src.gensim_helpers\n",
    "from src.gensim_helpers import (\n",
    "    compute_coherence_values,\n",
    "    make_bigrams,\n",
    "    remove_stopwords,\n",
    "    lemmatization,\n",
    "    sent_to_words,\n",
    "    format_topics_sentences,\n",
    "    get_bigrams_trigrams,\n",
    "    plot_coherence_scores,\n",
    "    compute_coherence_values,\n",
    "    print_top_words_gensim,\n",
    ")\n",
    "\n",
    "%aimport src.word_embedding_helpers\n",
    "from src.word_embedding_helpers import (\n",
    "    calculate_coherence,\n",
    "    get_descriptor,\n",
    "    TokenGenerator,\n",
    "    fit_nmf_for_num_topics,\n",
    "    compute_coherence_values_manually,\n",
    "    print_top_words,\n",
    "    get_docs_with_topics,\n",
    ")\n",
    "\n",
    "%aimport src.visualization_helpers\n",
    "from src.visualization_helpers import (\n",
    "    altair_datetime_heatmap,\n",
    "    plot_horiz_bar,\n",
    "    plot_horiz_bar_gensim,\n",
    "    pipe_get_topics,\n",
    "    get_top_words_per_topic,\n",
    "    get_docs_with_topics_v2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SIZE = 26\n",
    "MEDIUM_SIZE = 28\n",
    "BIGGER_SIZE = 30\n",
    "plt.rc(\"font\", size=SMALL_SIZE)  # controls default text sizes\n",
    "plt.rc(\"axes\", titlesize=SMALL_SIZE)  # fontsize of the axes title\n",
    "plt.rc(\"axes\", labelsize=MEDIUM_SIZE)  # fontsize of the x and y labels\n",
    "plt.rc(\"xtick\", labelsize=SMALL_SIZE)  # fontsize of the tick labels\n",
    "plt.rc(\"ytick\", labelsize=SMALL_SIZE)  # fontsize of the tick labels\n",
    "plt.rc(\"legend\", fontsize=SMALL_SIZE)  # legend fontsize\n",
    "plt.rc(\"figure\", titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "plt.rcParams[\"axes.facecolor\"] = \"white\"\n",
    "sns.set_style(\"darkgrid\", {\"legend.frameon\": False})\n",
    "sns.set_context(\"talk\", font_scale=0.95, rc={\"lines.linewidth\": 2.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"toc\"></a>\n",
    "\n",
    "## [Table of Contents](#table-of-contents)\n",
    "0. [About](#about)\n",
    "1. [User Inputs](#user-inputs)\n",
    "2. [Load joined data](#load-joined-data)\n",
    "3. [Topic modeling using TFIDF vectorization and NMF with Gensim Word2Vec word-embedding for selecting number of topics via topic coherence score](#topic-modeling-using-tfidf-vectorization-and-nmf-with-gensim-word2vec-word-embedding-for-selecting-number-of-topics-via-topic-coherence-score)\n",
    "   - 3.1. [Pre-processing for NMF](#pre-processing-for-nmf)\n",
    "   - 3.2. [NMF](#nmf)\n",
    "   - 3.3. [Build Word Embedding model with Gensim](#build-word-embedding-model-with-gensim)\n",
    "   - 3.4. [Use Word2Vec model to find number of topics](#use-word-to-vec-model-to-find-number-of-topics)\n",
    "   - 3.5. [NMF with selected number of topics from Word2Vec with coherence score](#nmf-with-selected-number-of-topics-from-word-to-vec-with-coherence-score)\n",
    "   - 3.6. [Exploring topics combined with source data](#exploring-topics-combined-with-source-data)\n",
    "4. [Topic modeling using Gensim NMF without TFIDF vectorization](#topic-modeling-using-gensim-nmf-without-tfidf-vectorization)\n",
    "   - 4.1. [Pre-processing for Gensim NMF](#pre-processing-for-gensim-nmf)\n",
    "   - 4.2. [Gensim tokenization](#gensim-tokenization)\n",
    "   - 4.3. [Gensim bi- and tri-gram models and lemmatization](#gensim-bi--and-tri-gram-models-and-lemmatization)\n",
    "   - 4.4. [Use Gensim to perform Bag-of-Words transformation](#use-gensim-to-perform-bag-of-words-transformation)\n",
    "   - 4.5. [Use Gensim NMF without TFIDF vectorization to find number of topics](#use-gensim-nmf-without-tfidf-vectorization-to-find-number-of-topics)\n",
    "   - 4.6. [NMF with selected number of topics from Gensim coherence score without TFIDF vectorization](#nmf-with-selected-number-of-topics-from-gensim-coherence-score-without-tfidf-vectorization)\n",
    "   - 4.7. [Exploring Gensim NMF topics combined with source data](#exploring-gensim-nmf-topics-combined-with-source-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"about\"></a>\n",
    "\n",
    "## 0. [About](#about)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will experiment with topic coherence approaches using Gensim to find an optimal number of topics from the joined news listings data in `data/processed/*_processed.csv`. This will be done separately using\n",
    "- `sklearn`'s NMF model with TFIDF vectorization, scored using manually calculated topic coherence via a word embedding model in Gensim\n",
    "- Gensim's NMF model without TFIDF vectorization, scored using Gensim's built-in coherence score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"user-inputs\"></a>\n",
    "\n",
    "## 1. [User Inputs](#user-inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define below the variables that are to be used throughout the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJ_ROOT_DIR = os.path.abspath(os.getcwd())\n",
    "processed_data_dir = os.path.join(PROJ_ROOT_DIR, \"data\", \"processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "publication_name = \"guardian\"\n",
    "\n",
    "# Data locations\n",
    "data_dir_path = os.path.join(processed_data_dir, f\"{publication_name}_processed.csv\")\n",
    "cloud_run = True\n",
    "\n",
    "# Custom stop words to include\n",
    "manual_stop_words = [\"nt\", \"ll\", \"ve\"]\n",
    "\n",
    "# Topic naming\n",
    "gensim_tfidf_mapping_dict = {\n",
    "    \"guardian\": {\n",
    "        \"component_1\": \"Gravity and Black holes - Hawking\",\n",
    "        \"component_2\": \"Rocket Launches - Testing\",\n",
    "        \"component_3\": \"Mars Exploration\",\n",
    "        \"component_4\": \"Academia\",  ##\n",
    "        \"component_5\": \"Studying Comets and Meteors\",\n",
    "        \"component_6\": \"Discover of Sub-Atomic particles\",\n",
    "        \"component_7\": \"Rocket Launches - Moon Landing\",\n",
    "        \"component_8\": \"Shuttle Missions and Crashes\",\n",
    "        \"component_9\": \"Global Warming\",\n",
    "        \"component_10\": \"ISS - USA and Russian segments\",\n",
    "        \"component_11\": \"Objects crashing into Earth\",\n",
    "        \"component_12\": \"Space Funding Bodies\",\n",
    "        \"component_13\": \"Imaging Stars - Astronomy\",  ##\n",
    "        \"component_14\": \"Saturn Research\",\n",
    "        \"component_15\": \"Planetary Research\",  ##\n",
    "    }\n",
    "}\n",
    "\n",
    "gensim_non_tfidf_mapping_dict = {\n",
    "    \"guardian\": {\n",
    "        0: \"Studying Comets and Meteors\",  #\n",
    "        1: \"Rocket Launches - Testing\",  #\n",
    "        2: \"Discover of Sub-Atomic particles\",  #\n",
    "        3: \"Learning and Memory\",  #\n",
    "        4: \"ISS\",  #\n",
    "        5: \"Brain Research\",  #\n",
    "        6: \"Academia\",  ##\n",
    "        7: \"Rocket Launches - Moon Landing\",  #\n",
    "        8: \"Pseudo space-science and Humanity - Opinion\",  #\n",
    "        9: \"Imaging Stars - Astronomy\",  #\n",
    "        10: \"Planetary Research\",  #\n",
    "        11: \"Global Warming and Climate Science\",  #\n",
    "        12: \"Dark Matter Theories\",  ##\n",
    "        13: \"Space Funding Bodies\",  ##\n",
    "        14: \"Mars Exploration\",  #\n",
    "    }\n",
    "}\n",
    "\n",
    "# General inputs\n",
    "limit = 30\n",
    "start = 10\n",
    "step = 1\n",
    "n_top_words = 10\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stop words from all packages\n",
    "# NLTK\n",
    "nltk_dir = os.path.join(os.path.expanduser(\"~\"), \"nltk_data\")\n",
    "if not os.path.isdir(nltk_dir):\n",
    "    nltk.download(\"punkt\")\n",
    "    nltk.download(\"wordnet\")\n",
    "    nltk.download(\"stopwords\")\n",
    "    nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk_stop_words = set(stopwords.words(\"english\"))\n",
    "# Spacy and sklearn\n",
    "spacy_stop_words = STOP_WORDS\n",
    "sklearn_stop_words = stop_words.ENGLISH_STOP_WORDS\n",
    "\n",
    "# Assemble manual list of stop words\n",
    "spacy_not_in_sklearn = set(spacy_stop_words) - set(sklearn_stop_words)\n",
    "nltk_not_in_sklearn = set(nltk_stop_words) - set(sklearn_stop_words)\n",
    "all_stop_words = set(\n",
    "    list(set(sklearn_stop_words))\n",
    "    + list(spacy_not_in_sklearn)\n",
    "    + list(nltk_not_in_sklearn)\n",
    ")\n",
    "\n",
    "# Manually add to stop words\n",
    "for manual_stop_word in manual_stop_words:\n",
    "    all_stop_words.add(manual_stop_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load-joined-data\"></a>\n",
    "\n",
    "## 2. [Load joined data](#load-joined-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by loading the joined data from from a publication, stored at `data/processed/<publication-name>_processed.csv`, into a `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir_path)\n",
    "df = df[[\"text\", \"year\"]]\n",
    "print(f\"Number of rows = {df.shape[0]}\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 500 if cloud_run else len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"topic-modeling-using-tfidf-vectorization-and-nmf-with-gensim-word2vec-word-embedding-for-selecting-number-of-topics-via-topic-coherence-score\"></a>\n",
    "\n",
    "## 3. [Topic modeling using TFIDF vectorization and NMF with Gensim Word2Vec word-embedding for selecting number of topics via topic coherence score](#topic-modeling-using-tfidf-vectorization-and-nmf-with-gensim-word2vec-word-embedding-for-selecting-number-of-topics-via-topic-coherence-score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will find the optimal number of topics for an NMF model from `sklearn` with TFIDF vectorization, using topic coherence from a word embedding (Gensim's Word2Vec) model. This is based on a modified version of a method used [elsewhere](https://github.com/derekgreene/topic-model-tutorial/blob/master/3%20-%20Parameter%20Selection%20for%20NMF.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_raw = df[\"text\"].str.lower().values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pre-processing-for-nmf\"></a>\n",
    "\n",
    "### 3.1. [Pre-processing for NMF](#pre-processing-for-nmf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll instantiate a TFIDF vectorizer object with the following changes from notebook `4_nlp_trials.ipynb` due to problems running Word2Vec (in `.wv.similarity()`, in the helper function `calculate_coherence_manually`) on the generated vectors\n",
    "- `strip_accents`\n",
    "  - was `\"ascii\"`, now set to its default value of `None`\n",
    "- `token_pattern`\n",
    "  - was `\"[a-z][a-z]+\"`, now set to its default value of `\"(?u)\\\\b\\\\w\\\\w+\\\\b\"`\n",
    "- `min_df`\n",
    "  - was `1`, now `20` (meaning word must occur 20 times in document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    tokenizer=None,\n",
    "    lowercase=True,\n",
    "    ngram_range=(1, 1),\n",
    "    stop_words=all_stop_words,\n",
    "    min_df=20,\n",
    "    max_features=None,\n",
    "    binary=False,\n",
    "    strip_accents=None,\n",
    "    token_pattern=\"(?u)\\\\b\\\\w\\\\w+\\\\b\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    steps=[(\"cleaner\", TextCleaner(split=False)), (\"vectorizer\", vectorizer)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In preparation for using an [NMF model on the corpus](https://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html#sphx-glr-auto-examples-applications-plot-topics-extraction-with-nmf-lda-py), we'll use this vectorizer to get the document-term matrix for the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_st = time()\n",
    "\n",
    "nmf_transformed = pipe.fit_transform(corpus_raw)\n",
    "docs_terms = pipe.named_steps[\"vectorizer\"].transform(corpus_raw)\n",
    "print(\n",
    "    f\"Created {docs_terms.shape[0]:0d} X {docs_terms.shape[1]:0d} \"\n",
    "    \"TF-IDF-normalized document-term matrix\"\n",
    ")\n",
    "\n",
    "total_minutes, total_seconds = divmod(time() - cell_st, 60)\n",
    "print(\n",
    "    f\"Cell exection time: {int(total_minutes):d} minutes, {total_seconds:.2f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now retrieve the mapping from feature integer indices to feature name.i.e. the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = pipe.named_steps[\"vectorizer\"].get_feature_names()\n",
    "print(f\"Vocabulary has {len(terms):0d} distinct terms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"nmf\"></a>\n",
    "\n",
    "### 3.2. [NMF](#nmf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will iterate over a desired number of topics and train an NMF model (using the `sklearn` library, as was done in `4_nlp_trials.ipynb`) on that number of topics, using the document-term matrix generated above. A helper function will be used to iterate over a range of number of topics and it will return a `list` of tuples of\n",
    "- `num_topics`\n",
    "- `model_transformed`\n",
    "  - NMF-transformed data\n",
    "- `factors_dict`\n",
    "  - factorization matrix/dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_st = time()\n",
    "\n",
    "topic_models = fit_nmf_for_num_topics(start, limit, random_state, docs_terms)\n",
    "\n",
    "total_minutes, total_seconds = divmod(time() - cell_st, 60)\n",
    "print(\n",
    "    f\"Cell exection time: {int(total_minutes):d} minutes, {total_seconds:.2f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"build-word-embedding-model-with-gensim\"></a>\n",
    "\n",
    "### 3.3. [Build Word Embedding model with Gensim](#build-word-embedding-model-with-gensim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, a custom Python class is used to format the documents to allow them to be used with Gensim's implementation of a `Word2Vec` model. The formatted documents are then trained on a `Word2Vec` model with 500 dimensions and the minimum document word frequency count of 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_st = time()\n",
    "\n",
    "docgen = TokenGenerator(corpus_raw, all_stop_words)\n",
    "w2v_model = Word2Vec(docgen, size=500, min_count=20, sg=1, seed=1)\n",
    "\n",
    "total_minutes, total_seconds = divmod(time() - cell_st, 60)\n",
    "print(\n",
    "    f\"Cell exection time: {int(total_minutes):d} minutes, {total_seconds:.2f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model has {len(w2v_model.wv.vocab):0d} terms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"use-word-to-vec-model-to-find-number-of-topics\"></a>\n",
    "\n",
    "### 3.4. [Use Word2Vec model to find number of topics](#use-word-to-vec-model-to-find-number-of-topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Word2Vec` model will be used to evaluate the trained NMF models, by calculating a coherence score for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_st = time()\n",
    "\n",
    "coherences = compute_coherence_values_manually(\n",
    "    topic_models, terms, n_top_words, w2v_model\n",
    ")\n",
    "\n",
    "total_minutes, total_seconds = divmod(time() - cell_st, 60)\n",
    "print(\n",
    "    f\"Cell exection time: {int(total_minutes):d} minutes, {total_seconds:.2f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coherence scores are graphed below against the number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coherence_scores(coherences, start, limit, step, (12, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. Ideally, the coherence scores would increase and then reach a plateau and the optimal number of topics would occur at the elbow in this curve - where the highest coherence score occurs before flattening out. Here, there appears to be a weak plateau between\n",
    "   - 14-18 topics (coherence score changes from approx. 0.405 to approx. 0.41 over this range)\n",
    "   - 24-30 topics (score changes from approx. 0.44 to approx. 0.45 over this range)\n",
    "   \n",
    "   Hyperparameter optimization could help improve the width of these plateaus and suggest stronger convergence towards an optimal number of topics, possibly by eliminating one such plateau.\n",
    "2. Over the range of number of topics from 14-30, the change in coherence score is 0.04 (approx. 10%).\n",
    "3. Since the overall maximum number of topics at the onset of the second plateau (24 topics) returns a coherence score that is only approx. 9% better from the plateau, we'll proceed with using 15 topics.\n",
    "4. The highest coherence score is annotated and occurs for 30 topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"nmf-with-selected-number-of-topics-from-word-to-vec-with-coherence-score\"></a>\n",
    "\n",
    "### 3.5. [NMF with selected number of topics from Word2Vec with coherence score](#nmf-with-selected-number-of-topics-from-word-to-vec-with-coherence-score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use 15 topics for further exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_n_topics = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll print out all the topics and their top ten terms found from the NMF model with the chosen number of topics based on coherence scores (15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_st = time()\n",
    "\n",
    "docs_topics = print_top_words(\n",
    "    topic_models,\n",
    "    best_n_topics,\n",
    "    n_top_words,\n",
    "    start,\n",
    "    terms,\n",
    "    docs_terms,\n",
    "    method=2,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "total_minutes, total_seconds = divmod(time() - cell_st, 60)\n",
    "print(\n",
    "    f\"Cell exection time: {int(total_minutes):d} minutes, {total_seconds:.2f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The topics and their top ten words are shown below, for the pre-determined choice of `random_state` of `42` specified in the Gensim NMF model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Top terms per topic, using random_state=42:\n",
    "Topic 0: universe galaxies black stars gravitational matter dark light waves telescope\n",
    "Topic 1: rocket spacex musk company falcon launch space flight virgin rockets\n",
    "Topic 2: mars beagle martian planet rover mission nasa lander life surface\n",
    "Topic 3: science people brain like says world research time human work\n",
    "Topic 4: comet rosetta philae lander comets dust mission surface esa probe\n",
    "Topic 5: higgs particle particles lhc physics cern matter boson energy collider\n",
    "Topic 6: moon lunar apollo armstrong nasa astronauts surface earth space aldrin\n",
    "Topic 7: shuttle nasa columbia space discovery launch astronauts mission station flight\n",
    "Topic 8: water ice climate life ocean carbon scientists sea surface warming\n",
    "Topic 9: station mir space russian iss crew peake astronaut russia soyuz\n",
    "Topic 10: asteroid asteroids earth impact rock object collision near miles hit\n",
    "Topic 11: space china satellites satellite uk government britain said chinese agency\n",
    "Topic 12: planets star planet stars kepler earth telescope astronomers life light\n",
    "Topic 13: cassini saturn titan pluto huygens rings planet spacecraft moons probe\n",
    "Topic 14: sun solar eclipse earth magnetic venus mercury atmosphere weather field\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. Topics are very similar to those found in `4_np_trials.ipynb` and appear clearly separable. The `Planetary Research` and `Global Warming` topics found here are variants of the corresponding topics found previously, based on top word. Differences in top words, relative to `4_nlp_trials.ipynb`, occur due to differences in TFIDF vectorization used here compared to those used previously, [as documented above](#pre-processing-for-nmf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the source article data, horizontally concatenated to the NMF document-topic matrix and the most popular topic for each article by taking the row-wise maximum of the document-topic matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_topics = get_docs_with_topics(\n",
    "    docs_topics=docs_topics,\n",
    "    num_topics=best_n_topics,\n",
    "    df_raw=df,\n",
    "    mapper_dict=gensim_tfidf_mapping_dict[publication_name],\n",
    ")\n",
    "display(df_with_topics.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now train a new NMF model with the chosen number of topics based on coherence score and get the corresponding factorization matrix (dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_st = time()\n",
    "\n",
    "nmf_best = NMF(n_components=best_n_topics, max_iter=700, random_state=random_state)\n",
    "nmf_transformed = nmf_best.fit_transform(docs_terms)\n",
    "\n",
    "total_minutes, total_seconds = divmod(time() - cell_st, 60)\n",
    "print(\n",
    "    f\"Cell exection time: {int(total_minutes):d} minutes, {total_seconds:.2f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabular versions of the top words per topic and of a an alternate method of obtaining the source data with topics (and probabilities) are shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    topic_word_best,\n",
    "    df_top_words_per_topic,\n",
    "    df_top_vals_per_topic,\n",
    ") = get_top_words_per_topic(\n",
    "    nmf_best,\n",
    "    vectorizer,\n",
    "    gensim_tfidf_mapping_dict[publication_name],\n",
    "    n_top_words,\n",
    "    best_n_topics,\n",
    "    False,\n",
    ")\n",
    "display(df_top_words_per_topic.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_topics_v2 = get_docs_with_topics_v2(\n",
    "    corpus_raw, nmf_transformed, gensim_tfidf_mapping_dict[publication_name], df\n",
    ")\n",
    "display(df_with_topics_v2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now use a helper function to generate a plot of topics and top 10 words (by how much each document is made up of the resulting topics) for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(24, 8))\n",
    "_ = sns.heatmap(\n",
    "    df_top_vals_per_topic.rename(columns=gensim_tfidf_mapping_dict[publication_name]).T,\n",
    "    annot=df_top_words_per_topic.rename(\n",
    "        columns=gensim_tfidf_mapping_dict[publication_name]\n",
    "    ).T,\n",
    "    fmt=\"\",\n",
    "    center=0,\n",
    "    cbar=False,\n",
    "    cmap=sns.diverging_palette(0, 255, sep=1, n=256),\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_xticklabels(ax.get_xticklabels(), ha=\"center\", rotation=0)\n",
    "ax.set_yticklabels(ax.get_yticklabels(), rotation=0)\n",
    "ax.set_title(\"Top Words per Topic\", fontweight=\"bold\", loc=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "1. In the above heatmap, the darker the shade of blue the stronger the relationship between the word and that topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_horiz_bar(\n",
    "    topic_word_best.T,\n",
    "    ptitle=\"\",\n",
    "    y_tick_mapper_list=list(gensim_tfidf_mapping_dict[publication_name].values()),\n",
    "    fig_size=(60, 8),\n",
    "    xspacer=0.001,\n",
    "    yspacer=0.3,\n",
    "    ytick_font_size=18,\n",
    "    title_font_size=20,\n",
    "    annot_font_size=16,\n",
    "    n_bars=10,\n",
    "    n_plots=topic_word_best.T.shape[1],\n",
    "    n_cols=best_n_topics,\n",
    "    show_bar_labels=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. These charts generally resemble those found in the previous notebook `4_nlp_trials.ipynb`, with exceptions due to differences in TFIDF vectorization [as mentioned earlier in this section](#nmf-with-selected-number-of-topics-from-word-to-vec-with-coherence-score)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exploring-topics-combined-with-source-data\"></a>\n",
    "\n",
    "### 3.6. [Exploring topics combined with source data](#exploring-topics-combined-with-source-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of occurrences of the most popular topic, shown separately for each year, is shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_by_timeframe = (\n",
    "    df_with_topics.groupby([\"most_popular_topic\", \"year\"])\n",
    "    .size()\n",
    "    .reset_index()\n",
    "    .sort_values(by=[\"most_popular_topic\", 0, \"year\"], ascending=False)\n",
    "    .rename(columns={0: \"count\"})\n",
    ")\n",
    "topics_by_timeframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will show a heatmap of the most popular topic by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altair_datetime_heatmap(\n",
    "    topics_by_timeframe,\n",
    "    x=\"year:O\",\n",
    "    y=\"most_popular_topic:N\",\n",
    "    xtitle=\"Year\",\n",
    "    ytitle=\"Most popular topic\",\n",
    "    tooltip=[\n",
    "        {\"title\": \"Year\", \"field\": \"year\", \"type\": \"ordinal\",},\n",
    "        {\n",
    "            \"title\": \"Most popular topic\",\n",
    "            \"field\": \"most_popular_topic\",\n",
    "            \"type\": \"nominal\",\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Number of occurrences as main topic\",\n",
    "            \"field\": \"count\",\n",
    "            \"type\": \"quantitative\",\n",
    "        },\n",
    "    ],\n",
    "    cmap=\"yelloworangered\",\n",
    "    legend_title=\"\",\n",
    "    color_by_col=\"count:Q\",\n",
    "    yscale=\"log\",\n",
    "    axis_tick_font_size=12,\n",
    "    axis_title_font_size=16,\n",
    "    title_font_size=20,\n",
    "    legend_fig_padding=10,  # default is 18\n",
    "    y_axis_title_alignment=\"left\",\n",
    "    fwidth=700,\n",
    "    fheight=450,\n",
    "    file_path=Path().cwd() / \"reports\" / \"figures\" / \"my_heatmap.html\",\n",
    "    save_to_html=False,\n",
    "    sort_y=[],\n",
    "    sort_x=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will show a bar chart of the number of occurrences of the `\"Space Funding Bodies\"` as the most popular topic, relative to the year 1980\n",
    "- this will approximate the public interest in changes in this topic over the years investigated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funds = (\n",
    "    topics_by_timeframe[\n",
    "        topics_by_timeframe[\"most_popular_topic\"] == \"Space Funding Bodies\"\n",
    "    ]\n",
    "    .set_index(\"year\")[\"count\"]\n",
    "    .sort_index()\n",
    ")\n",
    "funds / funds.loc[funds.index.min()]\n",
    "funds = funds / funds.loc[funds.index.min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "funds.plot(kind=\"bar\", ax=ax, rot=45, align=\"edge\", width=0.8)\n",
    "ax.set_title(\n",
    "    \"Cyclic variation in funding as main topic in article\",\n",
    "    fontsize=18,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "ax.set_xlabel(None)\n",
    "h = plt.ylabel(\"Funding\\n(rel. to 1981)\", labelpad=65, fontweight=\"bold\")\n",
    "h.set_rotation(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. The same implementation of NMF (from the `sklearn` library) and with the same number of topics was used. It is not surprising that the above chart is similar qualitatively (appearance of peaks and dips at locations very similar to those found earlier) and quantitatively (peak heights) to that found in the `4_nlp_trials.ipynb` notebook.\n",
    "2. Observed differences that do occur result in a peak in 2007 that is stronger than previously, a peak in 2013 that is weaker than previously and fewer occurrences of this topic in 2014, 2015 and 2016 than previously. These are due to the\n",
    "   - different hyperparameter settings needed in the TFIDF vectorization in order to the use Gensim's Word2Vec model to select the number of topics\n",
    "   - `random_state` enforced here, which was not done previously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"topic-modeling-using-gensim-nmf-without-tfidf-vectorization\"></a>\n",
    "\n",
    "## 4. [Topic modeling using Gensim NMF without TFIDF vectorization](#topic-modeling-using-gensim-nmf-without-tfidf-vectorization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll use Gensim's implementation of NMF, without TFIDF vectorization, to retrieve the optimal number of topics. This will be done without TFIDF Vectorization from either [`sklearn`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn-feature-extraction-text-tfidfvectorizer) or [`gensim`](https://radimrehurek.com/gensim/models/tfidfmodel.html#gensim.models.tfidfmodel.TfidfModel) itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_raw = df.loc[:, \"text\"].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pre-processing-for-gensim-nmf\"></a>\n",
    "\n",
    "### 4.1. [Pre-processing for Gensim NMF](#pre-processing-for-gensim-nmf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll clean the text of the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_st = time()\n",
    "\n",
    "pipe = Pipeline(steps=[(\"cleaner\", TextCleaner(split=False))])\n",
    "corpus_raw_cleaned = pipe.fit_transform(corpus_raw)\n",
    "\n",
    "total_minutes, total_seconds = divmod(time() - cell_st, 60)\n",
    "print(\n",
    "    f\"Cell exection time: {int(total_minutes):d} minutes, {total_seconds:.2f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gensim-tokenization\"></a>\n",
    "\n",
    "### 4.2. [Gensim tokenization](#gensim-tokenization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now tokenize the cleaned sentences into a list of words\n",
    "- this will convert each document into a list of lowercase tokens, ignoring tokens that are too short (length 2) or too long (length 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_st = time()\n",
    "\n",
    "# data_words = list(sent_to_words(corpus_raw))\n",
    "data_words = list(sent_to_words(corpus_raw_cleaned))\n",
    "\n",
    "total_minutes, total_seconds = divmod(time() - cell_st, 60)\n",
    "print(\n",
    "    f\"Cell exection time: {int(total_minutes):d} minutes, {total_seconds:.2f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gensim-bi--and-tri-gram-models-and-lemmatization\"></a>\n",
    "\n",
    "### 4.3. [Gensim bi- and tri-gram models and lemmatization](#gensim-bi--and-tri-gram-models-and-lemmatization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use Gensim's `Phrases` module to build bigram and trigram models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_st = time()\n",
    "\n",
    "bigram_model, trigram_model = get_bigrams_trigrams(data_words, 5, 100)\n",
    "\n",
    "total_minutes, total_seconds = divmod(time() - cell_st, 60)\n",
    "print(\n",
    "    f\"Cell exection time: {int(total_minutes):d} minutes, {total_seconds:.2f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll perform the following pre-processing\n",
    "- remove stopwords\n",
    "- (optional) create bigrams\n",
    "- (optional) lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_st = time()\n",
    "\n",
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words, all_stop_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops, bigram_model)\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(\n",
    "    data_words_nostops, allowed_postags=[\"NOUN\", \"ADJ\", \"VERB\", \"ADV\"]\n",
    ")\n",
    "\n",
    "total_minutes, total_seconds = divmod(time() - cell_st, 60)\n",
    "print(\n",
    "    f\"Cell exection time: {int(total_minutes):d} minutes, {total_seconds:.2f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"use-gensim-to-perform-bag-of-words-transformation\"></a>\n",
    "\n",
    "### 4.4. [Use Gensim to perform Bag-of-Words transformation](#use-gensim-to-perform-bag-of-words-transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll create a corpus comprising an assigned ID and corresponding frequency of words from the cleaned list of words (where stopwords were removed) above. This is Gensim's document conversion into a bag-of-words format, giving a list of tuples comprising token identifier and count (frequency)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_st = time()\n",
    "\n",
    "# Create Dictionary\n",
    "# id2word = corpora.Dictionary(data_lemmatized)\n",
    "id2word = corpora.Dictionary(data_words_nostops)\n",
    "\n",
    "# Term Document Frequency for corpus\n",
    "# corpus = [id2word.doc2bow(text) for text in data_lemmatized]\n",
    "corpus = [id2word.doc2bow(text) for text in data_words_nostops]\n",
    "\n",
    "total_minutes, total_seconds = divmod(time() - cell_st, 60)\n",
    "print(f\"Cell exection time: {int(total_minutes):d} minutes, {total_seconds:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"use-gensim-nmf-without-tfidf-vectorization-to-find-number-of-topics\"></a>\n",
    "\n",
    "### 4.5. [Use Gensim NMF without TFIDF vectorization to find number of topics](#use-gensim-nmf-without-tfidf-vectorization-to-find-number-of-topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now train Gensim's NMF model. A helper function below will iterate over the number of topics and compute the coherence score for each number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_st = time()\n",
    "\n",
    "model_dict, coherence_values = compute_coherence_values(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    # texts=data_lemmatized,\n",
    "    texts=data_words_nostops,\n",
    "    limit=limit,\n",
    "    start=start,\n",
    "    step=step,\n",
    "    chunk_size=chunk_size,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "total_minutes, total_seconds = divmod(time() - cell_st, 60)\n",
    "print(\n",
    "    f\"Cell exection time: {int(total_minutes):d} minutes, {total_seconds:.2f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coherence scores are graphed below by number of topics used, [with an annotation](https://matplotlib.org/2.0.0/users/annotations.html#annotating-with-text-with-box) showing the number of topics with the highest coherence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coherence_scores(coherence_values, start, limit, step, (12, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "1. The scores here are not directly comparable to those found earlier since\n",
    "   - the manual calculation of coherence scores earlier has not been verified against the [built-in gensim calculation](https://radimrehurek.com/gensim/models/coherencemodel.html#gensim.models.coherencemodel.CoherenceModel.get_coherence) used by this helper function\n",
    "   - pre-processing (text cleaning) was slightly different here than that used with the earlier approach\n",
    "   - the approach being used here (NMF without TFIDF) is different to that from earlier (word embedding with TFIDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. There isn't strong evidence of an increasing trend in the number of topics, nor of a plateau in the scores. While Gensim model hyperparameter optimization could be further explored, the scores do not show a preference for a specific choice of number of topics over the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"nmf-with-selected-number-of-topics-from-gensim-coherence-score-without-tfidf-vectorization\"></a>\n",
    "\n",
    "### 4.6. [NMF with selected number of topics from Gensim coherence score without TFIDF vectorization](#nmf-with-selected-number-of-topics-from-gensim-coherence-score-without-tfidf-vectorization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use 15 topics for further exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_n_topics = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_st = time()\n",
    "\n",
    "best_model = nmf.Nmf(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    num_topics=best_n_topics,\n",
    "    chunksize=chunk_size,  # no. of docs to be used in each training chunk\n",
    "    passes=10,\n",
    "    kappa=1.0,\n",
    "    minimum_probability=0.01,\n",
    "    w_max_iter=200,\n",
    "    w_stop_condition=0.0001,\n",
    "    h_max_iter=50,\n",
    "    h_stop_condition=0.001,\n",
    "    eval_every=10,\n",
    "    normalize=True,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "total_minutes, total_seconds = divmod(time() - cell_st, 60)\n",
    "print(\n",
    "    f\"Cell exection time: {int(total_minutes):d} minutes, {total_seconds:.2f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll print out all the topics found from the Gensim NMF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_top_words_gensim(\n",
    "    gensim_nmf_model=best_model,\n",
    "    mapper_dict=gensim_non_tfidf_mapping_dict[publication_name],\n",
    "    top_n_words=n_top_words,\n",
    "    random_state=random_state,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The topics and their top ten words are shown below, for the pre-determined choice of `random_state` of `42` specified in the Gensim NMF model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Top terms per cluster, using random_state=42:\n",
    "Topic 0: life time earth comet years scientists like species book dna\n",
    "Topic 1: space earth spacecraft satellites orbit satellite mission solar rocket moon\n",
    "Topic 2: particles universe particle theory physics higgs energy lhc matter time\n",
    "Topic 3: people memory like memories price day dont think remember things\n",
    "Topic 4: space station nasa shuttle astronauts launch mission said flight crew\n",
    "Topic 5: brain cells stem human tissue body cell neurons embryonic brains\n",
    "Topic 6: number atomic species new matter xenon human tellurium dark numbers\n",
    "Topic 7: says moon people like time lunar world going apollo think\n",
    "Topic 8: said time dawkins think people human like new dont world\n",
    "Topic 9: stars telescope star said light black astronomers galaxy years universe\n",
    "Topic 10: planet planets solar earth water sun scientists surface pluto ice\n",
    "Topic 11: work ice theory equation space climate surface time mathematical moduli\n",
    "Topic 12: research says new university scientists work matter scientific uk dark\n",
    "Topic 13: science scientific scientists research people public world climate new like\n",
    "Topic 14: mars mission life surface martian planet water nasa said scientists\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. Three new topics are introduced here, relative to the `TFIDF+NMF` or CorEx approaches. Some existing ones are modified in their appearance.\n",
    "2. One of these news topic names (`Dark Matter Theories`) is a weaker choice, based on the components words, and could be similar to the `Gravity and Black Holes` topic previously identified. Two topics could possibly be combined - `Brian Research` and `Learning and Memory` - resulting in 14 topics, as suggested by cross-validation with coherence-scores. NMF model hyper-parameter optimization could be explored to further study the topic selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_st = time()\n",
    "\n",
    "_ = plot_horiz_bar_gensim(\n",
    "    best_model,\n",
    "    id2word,\n",
    "    gensim_non_tfidf_mapping_dict[publication_name],\n",
    "    fig_size=(40, 35),\n",
    ")\n",
    "\n",
    "total_minutes, total_seconds = divmod(time() - cell_st, 60)\n",
    "print(\n",
    "    f\"Cell exection time: {int(total_minutes):d} minutes, {total_seconds:.2f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll append the topic to the same row as each document in the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_st = time()\n",
    "\n",
    "df_with_topics = format_topics_sentences(\n",
    "    best_model, corpus, df, gensim_non_tfidf_mapping_dict[publication_name]\n",
    ")\n",
    "display(df_with_topics.head(2))\n",
    "\n",
    "total_minutes, total_seconds = divmod(time() - cell_st, 60)\n",
    "print(\n",
    "    f\"Cell exection time: {int(total_minutes):d} minutes, {total_seconds:.2f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exploring-gensim-nmf-topics-combined-with-source-data\"></a>\n",
    "\n",
    "### 4.7. [Exploring Gensim NMF topics combined with source data](#exploring-gensim-nmf-topics-combined-with-source-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will show a heatmap of the most popular topic by year, found by Gensim's implementation of NMF (recall this was done above without TFIDF Vectorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_by_timeframe = (\n",
    "    df_with_topics.groupby([\"most_popular_topic\", \"year\"])\n",
    "    .size()\n",
    "    .reset_index()\n",
    "    .sort_values(by=[\"most_popular_topic\", 0, \"year\"], ascending=False)\n",
    "    .rename(columns={0: \"count\"})\n",
    ")\n",
    "topics_by_timeframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altair_datetime_heatmap(\n",
    "    topics_by_timeframe,\n",
    "    x=\"year:O\",\n",
    "    y=\"most_popular_topic:N\",\n",
    "    xtitle=\"Year\",\n",
    "    ytitle=\"Most popular topic\",\n",
    "    tooltip=[\n",
    "        {\"title\": \"Year\", \"field\": \"year\", \"type\": \"ordinal\",},\n",
    "        {\n",
    "            \"title\": \"Most popular topic\",\n",
    "            \"field\": \"most_popular_topic\",\n",
    "            \"type\": \"nominal\",\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Number of occurrences as main topic\",\n",
    "            \"field\": \"count\",\n",
    "            \"type\": \"quantitative\",\n",
    "        },\n",
    "    ],\n",
    "    cmap=\"yelloworangered\",\n",
    "    legend_title=\"\",\n",
    "    color_by_col=\"count:Q\",\n",
    "    yscale=\"log\",\n",
    "    axis_tick_font_size=12,\n",
    "    axis_title_font_size=16,\n",
    "    title_font_size=20,\n",
    "    legend_fig_padding=10,  # default is 18\n",
    "    y_axis_title_alignment=\"left\",\n",
    "    fwidth=700,\n",
    "    fheight=450,\n",
    "    file_path=Path().cwd() / \"reports\" / \"figures\" / \"my_heatmap.html\",\n",
    "    save_to_html=False,\n",
    "    sort_y=[],\n",
    "    sort_x=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will show a bar chart of the number of occurrences of the `\"Space Funding Bodies\"` as the most popular topic, relative to the year 1980\n",
    "- this will approximate the public interest in changes in this topic over the years investigated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funds = (\n",
    "    topics_by_timeframe[\n",
    "        topics_by_timeframe[\"most_popular_topic\"] == \"Space Funding Bodies\"\n",
    "    ]\n",
    "    .set_index(\"year\")[\"count\"]\n",
    "    .sort_index()\n",
    ")\n",
    "funds / funds.loc[funds.index.min()]\n",
    "funds = funds / funds.loc[funds.index.min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "funds.plot(kind=\"bar\", ax=ax, rot=45, align=\"edge\", width=0.8)\n",
    "ax.set_title(\n",
    "    \"Cyclic variation in funding as main topic in article\",\n",
    "    fontsize=18,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "ax.set_xlabel(None)\n",
    "h = plt.ylabel(\"Funding\\n(rel. to 1981)\", labelpad=65, fontweight=\"bold\")\n",
    "h.set_rotation(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. The multi-modal aspects of the `TFIDF+NMF` and CorEx implementations showing a broadened peak centered at 2014, a weaker peak in articles published under this topic in 2004 and a peak in 2007also appear here. The choice of this topic was not as difficult here as it was for two of the other assigned topic names.\n",
    "2. Peak heights are distinctly weaker than those found in `TFIDF+NMF` and CorEx spproaches indicating documents previously assigned to this topic are now being placed in another topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"conclusions\"></a>\n",
    "\n",
    "## 5. [Conclusions](#conclusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. With `TFIDF` vectorization, `sklearn`'s `NMF` found two new topics than those previously seen using `sklearn`'s NMF with TFIDF in `4_nlp_trials.ipynb`. Due to the similarities to the previously used `NMF` approach, the other identified topics here were in good agreement with those found earlier, as expected. The number of topics was chosen at the onset of a plateau in coherence scores using a word embedding model, however a weakly increasing trend (improvement) in scores was noticed after the plateau and was not considered when selecting the optimal number of topics. This offers reasonable validation of the number of topics found by the NMF+TFIDF/CorEx approaches in previous notebooks (`4_nlp_trials.ipynb` and `5_corex_nlp_trials.ipynb`).\n",
    "2. Without `TFIDF` vectorization, Gensim's `NMF` found three new topics that were not observed previously using `sklearn`'s NMF with TFIDF in `4_nlp_trials.ipynb`. A few of the other topics found using Gensim's `NMF` (without TFIDF) were a variant of those found with that previous notebook's NMF approach - the agreement between topics found here and those from the prevoius notebook was not as good as that noticed with the above approach (NMF with TFIDF from section 3 in this notebook). The number of topics has some evidence of being one too many. If such an approach (Gensim's `NMF` without `TFIDF` vectorization) is to be used further, then the performance of model hyperparameter optimization with 14 and 15 topics should be investigated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
