{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Gensim NLP trials](#gensim-nlp-trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from itertools import combinations\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "from IPython.display import display\n",
    "\n",
    "import altair as alt\n",
    "import gensim.corpora as corpora\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport src.pipe_helpers\n",
    "from src.pipe_helpers import TextCleaner\n",
    "\n",
    "%aimport src.gensim_helpers\n",
    "from src.gensim_helpers import (\n",
    "    compute_coherence_values,\n",
    "    make_bigrams,\n",
    "    remove_stopwords,\n",
    "    sent_to_words,\n",
    "    format_topics_sentences,\n",
    "    get_bigrams_trigrams,\n",
    "    plot_coherence_scores,\n",
    "    compute_coherence_values,\n",
    ")\n",
    "\n",
    "%aimport src.visualization_helpers\n",
    "from src.visualization_helpers import (\n",
    "    altair_datetime_heatmap,\n",
    "    plot_horiz_bar,\n",
    "    plot_horiz_bar_gensim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SIZE = 26\n",
    "MEDIUM_SIZE = 28\n",
    "BIGGER_SIZE = 30\n",
    "plt.rc(\"font\", size=SMALL_SIZE)  # controls default text sizes\n",
    "plt.rc(\"axes\", titlesize=SMALL_SIZE)  # fontsize of the axes title\n",
    "plt.rc(\"axes\", labelsize=MEDIUM_SIZE)  # fontsize of the x and y labels\n",
    "plt.rc(\"xtick\", labelsize=SMALL_SIZE)  # fontsize of the tick labels\n",
    "plt.rc(\"ytick\", labelsize=SMALL_SIZE)  # fontsize of the tick labels\n",
    "plt.rc(\"legend\", fontsize=SMALL_SIZE)  # legend fontsize\n",
    "plt.rc(\"figure\", titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "plt.rcParams[\"axes.facecolor\"] = \"white\"\n",
    "sns.set_style(\"darkgrid\", {\"legend.frameon\": False})\n",
    "sns.set_context(\"talk\", font_scale=0.95, rc={\"lines.linewidth\": 2.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"toc\"></a>\n",
    "\n",
    "## [Table of Contents](#table-of-contents)\n",
    "0. [About](#about)\n",
    "1. [User Inputs](#user-inputs)\n",
    "2. [Load joined data](#load-joined-data)\n",
    "3. [Topic modeling using Gensim NMF with TFIDF vectorization](#topic-modeling-using-gensim-nmf-with-tfidf-vectorization)\n",
    "4. [Topic modeling using Gensim NMF without TFIDF vectorization](#topic-modeling-using-gensim-nmf-without-tfidf-vectorization)\n",
    "   - 4.1. [Pre-processing for Gensim NMF](#pre-processing-for-gensim-nmf)\n",
    "   - 4.2. [Gensim NMF](#gensim-nmf)\n",
    "   - 4.3. [Exploring Gensim NMF topics combined with source data](#exploring-gensim-nmf-topics-combined-with-source-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"about\"></a>\n",
    "\n",
    "## 0. [About](#about)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will experiment with NLP models on the joined news listings data in `data/processed/*_processed.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"user-inputs\"></a>\n",
    "\n",
    "## 1. [User Inputs](#user-inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define below the variables that are to be used throughout the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "publication_name = \"guardian\"\n",
    "\n",
    "# Data locations\n",
    "data_dir_path = str(\n",
    "    Path().cwd() / \"data\" / \"processed\" / f\"{publication_name}_processed.csv\"\n",
    ")\n",
    "cloud_run = True\n",
    "\n",
    "# Custom stop words to include\n",
    "manual_stop_words = [\"nt\", \"ll\", \"ve\"]\n",
    "\n",
    "# Topic naming\n",
    "gensim_non_tfidf_mapping_dict = {\n",
    "    \"guardian\": {\n",
    "        0: \"Space Funding Bodies\",\n",
    "        1: \"Rocket Launches - Moon Landing and ISS\",\n",
    "        2: \"Discover of Sub-Atomic particles\",\n",
    "        3: \"Mars Exploration\",\n",
    "        4: \"Planetary Research\",\n",
    "        5: \"Shuttle Missions and Crashes\",\n",
    "        6: \"Academia\",\n",
    "        7: \"Gravity and Black Holes - Hawking\",\n",
    "        8: \"Black Body Radiation\",\n",
    "        9: \"Dark Matter theories\",\n",
    "        10: \"Pseudo space-science and Humanity - Opinion\",\n",
    "        11: \"Studying Comets and Meteors\",\n",
    "        12: \"Global Warming\",\n",
    "        13: \"Space Funding Bodies\",\n",
    "        14: \"Learning and Memory\",\n",
    "    }\n",
    "}\n",
    "\n",
    "# General inputs\n",
    "limit = 25\n",
    "start = 10\n",
    "step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_coherence(w2v_model, term_rankings):\n",
    "    overall_coherence = 0.0\n",
    "    for topic_index in range(len(term_rankings)):\n",
    "        # check each pair of terms\n",
    "        pair_scores = []\n",
    "        for pair in combinations(term_rankings[topic_index], 2):\n",
    "            pair_scores.append(w2v_model.wv.similarity(pair[0], pair[1]))\n",
    "        # get the mean for all pairs in this topic\n",
    "        topic_score = sum(pair_scores) / len(pair_scores)\n",
    "        overall_coherence += topic_score\n",
    "    # get the mean score across all topics\n",
    "    return overall_coherence / len(term_rankings)\n",
    "\n",
    "\n",
    "def get_descriptor(all_terms, H, topic_index, top):\n",
    "    # reverse sort the values to sort the indices\n",
    "    top_indices = np.argsort(H[topic_index, :])[::-1]\n",
    "    # now get the terms corresponding to the top-ranked indices\n",
    "    top_terms = []\n",
    "    for term_index in top_indices[0:top]:\n",
    "        top_terms.append(all_terms[term_index])\n",
    "    return top_terms\n",
    "\n",
    "\n",
    "class TokenGenerator:\n",
    "    def __init__(self, documents, stopwords):\n",
    "        self.documents = documents\n",
    "        self.stopwords = stopwords\n",
    "        self.tokenizer = re.compile(r\"(?u)\\b\\w\\w+\\b\")\n",
    "\n",
    "    def __iter__(self):\n",
    "        print(\"Building Word2Vec model ...\")\n",
    "        for doc in self.documents:\n",
    "            tokens = []\n",
    "            for tok in self.tokenizer.findall(doc):\n",
    "                if tok in self.stopwords:\n",
    "                    tokens.append(\"<stopword>\")\n",
    "                elif len(tok) >= 2:\n",
    "                    tokens.append(tok)\n",
    "            yield tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stop words from all packages\n",
    "# NLTK\n",
    "if not ((Path.cwd().parents[1]) / \"nltk_data\").exists():\n",
    "    nltk.download(\"punkt\")\n",
    "    nltk.download(\"wordnet\")\n",
    "    nltk.download(\"stopwords\")\n",
    "    nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk_stop_words = set(stopwords.words(\"english\"))\n",
    "# Spacy and sklearn\n",
    "spacy_stop_words = STOP_WORDS\n",
    "sklearn_stop_words = stop_words.ENGLISH_STOP_WORDS\n",
    "\n",
    "# Assemble manual list of stop words\n",
    "spacy_not_in_sklearn = set(spacy_stop_words) - set(sklearn_stop_words)\n",
    "nltk_not_in_sklearn = set(nltk_stop_words) - set(sklearn_stop_words)\n",
    "all_stop_words = set(\n",
    "    list(set(sklearn_stop_words))\n",
    "    + list(spacy_not_in_sklearn)\n",
    "    + list(nltk_not_in_sklearn)\n",
    ")\n",
    "\n",
    "# Manually add to stop words\n",
    "for manual_stop_word in manual_stop_words:\n",
    "    all_stop_words.add(manual_stop_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load-joined-data\"></a>\n",
    "\n",
    "## 2. [Load joined data](#load-joined-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by loading the joined data from from a publication, stored at `data/processed/<publication-name>_processed.csv`, into a `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(Path(data_dir_path))\n",
    "df = df[[\"text\", \"year\"]]\n",
    "print(df.shape[0])\n",
    "display(df.head())\n",
    "# print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"text\"] = df[\"text\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_raw = df.loc[:, \"text\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer(\n",
    "#     tokenizer=None,\n",
    "#     lowercase=True,\n",
    "#     ngram_range=(1, 1),\n",
    "#     stop_words=all_stop_words,\n",
    "#     min_df=20,\n",
    "#     max_features=None,\n",
    "#     binary=False,\n",
    "#     strip_accents=None,\n",
    "# )\n",
    "vectorizer = TfidfVectorizer(\n",
    "    tokenizer=None,\n",
    "    preprocessor=None,\n",
    "    stop_words=all_stop_words,  # \"all_stop_words\" or \"english\"\n",
    "    lowercase=True,\n",
    "    ngram_range=(1, 1),\n",
    "    max_df=1.0,\n",
    "    min_df=1,\n",
    "    max_features=None,\n",
    "    binary=False,\n",
    "    strip_accents=\"ascii\",\n",
    "    token_pattern=\"[a-z][a-z]+\",\n",
    ")\n",
    "pipe = Pipeline(\n",
    "    steps=[(\"cleaner\", TextCleaner(split=False)), (\"vectorizer\", vectorizer),]\n",
    ")\n",
    "\n",
    "docs_terms = vectorizer.fit_transform(corpus_raw)\n",
    "print(\n",
    "    f\"Created {docs_terms.shape[0]:0d} X {docs_terms.shape[1]:0d} TF-IDF-normalized document-term matrix\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "print(\"Vocabulary has %d distinct terms\" % len(terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_st = time()\n",
    "\n",
    "topic_models = []\n",
    "for num_topics in range(start, limit + 1):\n",
    "    print(f\"Applying NMF with {num_topics:0d} topics...\")\n",
    "    model = NMF(n_components=num_topics, max_iter=200)\n",
    "    model_transformed = model.fit_transform(docs_terms)\n",
    "    factors_dict = model.components_\n",
    "    topic_models.append((num_topics, model_transformed, factors_dict))\n",
    "\n",
    "total_minutes, total_seconds = divmod(time() - cell_st, 60)\n",
    "print(\n",
    "    f\"Cell exection time: {int(total_minutes):d} minutes, {total_seconds:.2f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_st = time()\n",
    "\n",
    "docgen = TokenGenerator(corpus_raw, all_stop_words)\n",
    "w2v_model = gensim.models.Word2Vec(docgen, size=500, min_count=20, sg=1)\n",
    "\n",
    "total_minutes, total_seconds = divmod(time() - cell_st, 60)\n",
    "print(\n",
    "    f\"Cell exection time: {int(total_minutes):d} minutes, {total_seconds:.2f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model has %d terms\" % len(w2v_model.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_st = time()\n",
    "\n",
    "k_values = []\n",
    "coherences = []\n",
    "for (k, W, H) in topic_models:\n",
    "    # Get all of the topic descriptors - the term_rankings, based on top 10 terms\n",
    "    term_rankings = []\n",
    "    for topic_index in range(k):\n",
    "        term_rankings.append(get_descriptor(terms, H, topic_index, 10))\n",
    "    # Now calculate the coherence based on our Word2vec model\n",
    "    k_values.append(k)\n",
    "    coherences.append(calculate_coherence(w2v_model, term_rankings))\n",
    "    print(\"K=%02d: Coherence=%.4f\" % (k, coherences[-1]))\n",
    "\n",
    "total_minutes, total_seconds = divmod(time() - cell_st, 60)\n",
    "print(\n",
    "    f\"Cell exection time: {int(total_minutes):d} minutes, {total_seconds:.2f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(13, 7))\n",
    "# create the line plot\n",
    "ax = plt.plot(k_values, coherences)\n",
    "plt.xticks(k_values)\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Mean Coherence\")\n",
    "# add the points\n",
    "plt.scatter(k_values, coherences, s=120)\n",
    "# find and annotate the maximum point on the plot\n",
    "ymax = max(coherences)\n",
    "xpos = coherences.index(ymax)\n",
    "best_k = k_values[xpos]\n",
    "plt.annotate(\n",
    "    \"k=%d\" % best_k,\n",
    "    xy=(best_k, ymax),\n",
    "    xytext=(best_k, ymax),\n",
    "    textcoords=\"offset points\",\n",
    "    fontsize=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 15\n",
    "# get the model that we generated earlier.\n",
    "W = topic_models[k - start][1]\n",
    "H = topic_models[k - start][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic_index in range(k):\n",
    "    descriptor = get_descriptor(terms, H, topic_index, 10)\n",
    "    str_descriptor = \", \".join(descriptor)\n",
    "    print(\"Topic %02d: %s\" % (topic_index + 1, str_descriptor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"topic-modeling-using-gensim-nmf-without-tfidf-vectorization\"></a>\n",
    "\n",
    "## 4. [Topic modeling using Gensim NMF without TFIDF vectorization](#topic-modeling-using-gensim-nmf-without-tfidf-vectorization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll use Gensim's implementation of NMF, without TFIDF vectorization, to retrieve topics. This will be done without TFIDF Vectorization from either [`sklearn`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn-feature-extraction-text-tfidfvectorizer) or [`gensim`](https://radimrehurek.com/gensim/models/tfidfmodel.html#gensim.models.tfidfmodel.TfidfModel) itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pre-processing-for-gensim-nmf\"></a>\n",
    "\n",
    "### 4.1. [Pre-processing for Gensim NMF](#pre-processing-for-gensim-nmf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll clean the text of the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_st = time()\n",
    "\n",
    "pipe = Pipeline(steps=[(\"cleaner\", TextCleaner(split=False))])\n",
    "corpus_raw_cleaned = pipe.fit_transform(corpus_raw)\n",
    "\n",
    "total_minutes, total_seconds = divmod(time() - cell_st, 60)\n",
    "print(\n",
    "    f\"Cell exection time: {int(total_minutes):d} minutes, {total_seconds:.2f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now tokenize the cleaned sentences into a list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_st = time()\n",
    "\n",
    "# data_words = list(sent_to_words(corpus_raw))\n",
    "data_words = list(sent_to_words(corpus_raw_cleaned))\n",
    "\n",
    "total_minutes, total_seconds = divmod(time() - cell_st, 60)\n",
    "print(\n",
    "    f\"Cell exection time: {int(total_minutes):d} minutes, {total_seconds:.2f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use Gensim's `Phrases` module to build bigram and trigram models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_st = time()\n",
    "\n",
    "bigram_model, trigram_model = get_bigrams_trigrams(data_words, 5, 100)\n",
    "\n",
    "total_minutes, total_seconds = divmod(time() - cell_st, 60)\n",
    "print(\n",
    "    f\"Cell exection time: {int(total_minutes):d} minutes, {total_seconds:.2f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll perform the following pre-processing\n",
    "- remove stopwords\n",
    "- (optional) create bigrams\n",
    "- (optional) lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_st = time()\n",
    "\n",
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words, all_stop_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(\n",
    "    data_words_nostops, allowed_postags=[\"NOUN\", \"ADJ\", \"VERB\", \"ADV\"]\n",
    ")\n",
    "\n",
    "total_minutes, total_seconds = divmod(time() - cell_st, 60)\n",
    "print(\n",
    "    f\"Cell exection time: {int(total_minutes):d} minutes, {total_seconds:.2f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll create a corpus comprising an assigned ID and corresponding frequency of words from the cleaned list of words (where stopwords were removed) above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_st = time()\n",
    "\n",
    "# Create Dictionary\n",
    "# id2word = corpora.Dictionary(data_lemmatized)\n",
    "id2word = corpora.Dictionary(data_words_nostops)\n",
    "\n",
    "# Term Document Frequency for corpus\n",
    "# corpus = [id2word.doc2bow(text) for text in data_lemmatized]\n",
    "corpus = [id2word.doc2bow(text) for text in data_words_nostops]\n",
    "\n",
    "total_minutes, total_seconds = divmod(time() - cell_st, 60)\n",
    "print(f\"Cell exection time: {int(total_minutes):d} minutes, {total_seconds:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gensim-nmf\"></a>\n",
    "\n",
    "### 4.2. [Gensim NMF](#gensim-nmf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now train Gensim's NMF model. A helper function below will iterate over the number of topics and compute the coherence score for each number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_st = time()\n",
    "\n",
    "model_dict, coherence_values = compute_coherence_values(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    # texts=data_lemmatized,\n",
    "    texts=data_words_nostops,\n",
    "    limit=limit,\n",
    "    start=start,\n",
    "    step=step,\n",
    ")\n",
    "\n",
    "total_minutes, total_seconds = divmod(time() - cell_st, 60)\n",
    "print(\n",
    "    f\"Cell exection time: {int(total_minutes):d} minutes, {total_seconds:.2f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coherence scores are graphed below by number of topics used, with an [annotation showing](https://matplotlib.org/2.0.0/users/annotations.html#annotating-with-text-with-box) the number of topics with the highest coherence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coherence_scores(coherence_values, start, limit, step, (8, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. There is evidence of a increasing trend in the number of topics, with a periodicity appearing approx. every 5 topics. This could be an artifact of the choice of other hyperparameters chosen in the Gensim NMF model. Optimization of these could be more revealing for choosing the best NMF model here.\n",
    "2. The best score occurs for 20 topics and is only approx. 0.03 larger than that for the number of topics used in NMF/CorEx approaches (15)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the difference between the previously used 15 topics and highest coherence score here (20) is so small, we'll use 15 topics for further exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model_dict[15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll print out all the topics found from the Gensim NMF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twords = {}\n",
    "for topic, word in best_model.show_topics(num_topics=len(gensim_non_tfidf_mapping_dict[publication_name]), num_words=10):\n",
    "    words_cleaned = re.sub(\"[^A-Za-z ]+\", \"\", word)\n",
    "    twords[topic] = words_cleaned\n",
    "    print(f\"Topic {topic}:\", words_cleaned.replace(\"  \", \" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Topic 0: science scientific research scientists public people uk world technology new\n",
    "Topic 1: people like says think dont time things going thats know\n",
    "Topic 2: ice climate change energy carbon global sea particles water warming\n",
    "Topic 3: time theory work physics scientific world human way quantum new\n",
    "Topic 4: space said satellites satellite rocket earth launch orbit says company\n",
    "Topic 5: universe matter dark particles light stars black gravitational particle theory\n",
    "Topic 6: said dawkins university research years people work like memory black\n",
    "Topic 7: says brain new research cells human work use university body\n",
    "Topic 8: moon lunar earth surface said mission apollo time moons spacecraft\n",
    "Topic 9: planet earth planets solar sun star asteroid orbit years astronomers\n",
    "Topic 10: comet new solar mission spacecraft sun rosetta launch comets philae\n",
    "Topic 11: stars life planets telescope light memory star cells way years\n",
    "Topic 12: space station shuttle astronauts nasa mission astronaut crew flight russian\n",
    "Topic 13: life water mars planet surface scientists said martian space atmosphere\n",
    "Topic 14: mars nasa mission missions nasas landing going launch earth astronauts\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_st = time()\n",
    "\n",
    "_ = plot_horiz_bar_gensim(\n",
    "    best_model,\n",
    "    id2word,\n",
    "    gensim_non_tfidf_mapping_dict[publication_name],\n",
    "    fig_size=(40, 35),\n",
    ")\n",
    "\n",
    "total_minutes, total_seconds = divmod(time() - cell_st, 60)\n",
    "print(f\"Cell exection time: {int(total_minutes):d} minutes, {total_seconds:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll append the topic to the same row as each document in the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_st = time()\n",
    "\n",
    "df_with_topics = format_topics_sentences(\n",
    "    best_model, corpus, df, gensim_non_tfidf_mapping_dict[publication_name]\n",
    ")\n",
    "display(df_with_topics.head(2))\n",
    "\n",
    "total_minutes, total_seconds = divmod(time() - cell_st, 60)\n",
    "print(\n",
    "    f\"Cell exection time: {int(total_minutes):d} minutes, {total_seconds:.2f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exploring-gensim-nmf-topics-combined-with-source-data\"></a>\n",
    "\n",
    "### 4.3. [Exploring Gensim NMF topics combined with source data](#exploring-gensim-nmf-topics-combined-with-source-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will show a heatmap of the most popular topic by year, found by Gensim's implementation of NMF (recall this was done above without TFIDF Vectorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_by_timeframe = (\n",
    "    df_with_topics.groupby([\"most_popular_topic\", \"year\"])\n",
    "    .size()\n",
    "    .reset_index()\n",
    "    .sort_values(by=[\"most_popular_topic\", 0, \"year\"], ascending=False)\n",
    "    .rename(columns={0: \"count\"})\n",
    ")\n",
    "topics_by_timeframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altair_datetime_heatmap(\n",
    "    topics_by_timeframe,\n",
    "    x=\"year:O\",\n",
    "    y=\"most_popular_topic:N\",\n",
    "    xtitle=\"Year\",\n",
    "    ytitle=\"Most popular topic\",\n",
    "    tooltip=[\n",
    "        {\"title\": \"Year\", \"field\": \"year\", \"type\": \"ordinal\",},\n",
    "        {\n",
    "            \"title\": \"Most popular topic\",\n",
    "            \"field\": \"most_popular_topic\",\n",
    "            \"type\": \"nominal\",\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Number of occurrences as main topic\",\n",
    "            \"field\": \"count\",\n",
    "            \"type\": \"quantitative\",\n",
    "        },\n",
    "    ],\n",
    "    cmap=\"yelloworangered\",\n",
    "    legend_title=\"\",\n",
    "    color_by_col=\"count:Q\",\n",
    "    yscale=\"log\",\n",
    "    axis_tick_font_size=12,\n",
    "    axis_title_font_size=16,\n",
    "    title_font_size=20,\n",
    "    legend_fig_padding=10,  # default is 18\n",
    "    y_axis_title_alignment=\"left\",\n",
    "    fwidth=700,\n",
    "    fheight=450,\n",
    "    file_path=Path().cwd() / \"reports\" / \"figures\" / \"my_heatmap.html\",\n",
    "    save_to_html=False,\n",
    "    sort_y=[],\n",
    "    sort_x=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will show a bar chart of the number of occurrences of the `\"Space Funding Bodies\"` as the most popular topic, relative to the year 1980\n",
    "- this will approximate the public interest in changes in this topic over the years investigated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funds = (\n",
    "    topics_by_timeframe[\n",
    "        # topics_by_timeframe[\"most_popular_topic\"] == \"Space Funding Bodies\"\n",
    "        topics_by_timeframe[\"most_popular_topic\"]\n",
    "        == 0\n",
    "    ]\n",
    "    .set_index(\"year\")[\"count\"]\n",
    "    .sort_index()\n",
    ")\n",
    "funds / funds.loc[funds.index.min()]\n",
    "funds = funds / funds.loc[funds.index.min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "funds.plot(kind=\"bar\", ax=ax, rot=45, align=\"edge\", width=0.8)\n",
    "ax.set_title(\n",
    "    \"Cyclic variation in funding as main topic in article\",\n",
    "    fontsize=18,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "ax.set_xlabel(None)\n",
    "h = plt.ylabel(\"Funding\\n(rel. to 1981)\", labelpad=65, fontweight=\"bold\")\n",
    "h.set_rotation(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. Both the `sklearn` NMF and CorEx implementations show a broadened peak centered at 2014 and a weaker+narrower peak in articles published under this topic in 2004. The latter appears here, and is the strongest peak, while the former (2014 peak) is not evident."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
